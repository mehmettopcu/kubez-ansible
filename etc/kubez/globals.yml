---
#####################
# kubernetes options
#####################
# Enable an high availability kubernetes cluster.
#enable_kubernetes_ha: "no"

kube_release: 1.28.0

cluster_cidr: "172.30.0.0/16"
service_cidr: "10.254.0.0/16"

#Network interface is optional, the default value
#is eth0.
#network_interface: "eth0"

# This should be a VIP, an unused IP on your network that will float between
# the hosts running keepalived for high-availability.
#kube_vip_address: ""

# Enable haproxy and keepalived
# This configuration is usually enabled when self-created VMs require high availability.
#enable_haproxy: "no"

# Listen port for kubernetes.
# When enabling HAProxy + keepalived, it is recommended to use port 8443
#kube_vip_port: 6443

# Kubernetes network cni options
#enable_calico: "no"

# kubernetes image repository address, default is Aliyun, users can configure according to actual situation
# you can use the Pixiu community image repository: docker.io/pixiuio
image_repository: "registry.k8s.io"

# Custom image repository
app_image_repository: "harbor.cloud.pixiuio.com/pixiuio"

# Custom REPO repository
repo_dir: "/etc/kubez/repo"

###############
# Host Options
###############
# Automatically reset the hostname of the node
# Does not take effect on Rocky systems
#set_hostname: "yes"

##################
# Runtime Options
##################
# runtime docker version
# Find the appropriate version using apt-cache madison docker-ce
docker_release: ""
# Runtime containerd version
containerd_release: ""

# Custom Docker data storage directory
docker_data_dir: "{{ runtime_data_dir }}"
# Custom containerd data storage directory
containerd_data_dir: "{{ runtime_data_dir }}"

####################
# Kubernetes (1.24.0+) uses runtime as Docker
####################
# Binary file image of cir-dockerd
#cri_dockerd_image: "harbor.cloud.pixiuio.com/pixiuio/cri-dockerd:v0.3.10"

#####################
# keepalived options
#####################
# Arbitrary unique number from 0..255
#keepalived_virtual_router_id: "68"

####################
# Dashboard options
####################
#enable_dashboard: "no"
#dashboard_chart_version: 6.0.0

#dashboard_name: kubernetes-dashboard
#dashboard_namespace: "{{ kubez_namespace }}"
#dashboard_vip_address: ""

# Helm repository configuration, default is the Pixiu helm chart repository
#dashboard_repo_name: "{{ default_repo_name }}"
#dashboard_repo_url: "{{ default_repo_url }}"
#dashboard_path: pixiuio/kubernetes-dashboard
#dashboard_version: 6.0.0

#######################
# StorageClass Options
#######################
#enable_nfs: "yes"
#enable_nfs_csi: "{{ enable_nfs }}"

#nfs_storage_class: managed-nfs-storage
#nfs_server: "{{ hostvars[groups['storage'][0]]['ansible_' + api_interface]['ipv4']['address'] }}"
#nfs_share: /data/share

#############################
# Pixiu-localstorage Options
#############################
#enable_pixiu_localstorage: "no"

#enable_rbd_provisioner: "no"
#pool_name: kube

# Ceph monitors, comma delimited. This parameter is required.
#monitors: 172.16.60.102:6789

# Ceph auth get-key client.admin | base64
#admin_key:

# Ceph osd pool create pool_name 8 8
# Ceph auth add client.pool_name mon 'allow r' osd 'allow rwx pool=pool_name'
# Ceph auth get-key client.pool_name | base64
#pool_key:

###############
# Minio Options
###############
# https://github.com/minio/minio
#enable_minio: "no"

#minio_name: minio
#minio_namespace: "{{ kubez_namespace }}"

#minio_storage_class: managed-nfs-storage
#minio_storage_size: 500Gi
# Recommended for production environment: 16Gi
#minio_memory_size: 4Gi

# applicable only for MinIO distributed mod
# recommended for production environment: 16
#minio_replicas: 4
#minio_rootUser: minioadmin
#minio_rootPassword: minioadmin

#####################
# Prometheus Options
#####################
#enable_prometheus: "no"
#prometheus_namespace: "{{ kubez_namespace }}"

# Whether to enable persistent storage for prometheus-server, default is enabled
#Must be 'true' or 'false', otherwise it will be ignored by the helm_toolbox module
#enable_prometheus_server_storage: 'true'
#prometheus_server_storage_class: managed-nfs-storage
#prometheus_server_persistent_volume_size: 8Gi

# Whether to enable prometheus-alertmanager, default is enabled
# Must be 'true' or 'false', otherwise it will be ignored by the helm_toolbox module
#enable_prometheus_alertmanager: 'true'
#prometheus_alertmanager_persistent_volume_size: 2Gi

# Helm repository configuration, default is the Pixiu helm chart repository
#prometheus_repo_name: "{{ default_repo_name }}"
#prometheus_repo_url: "{{ default_repo_url }}"
#prometheus_path: pixiuio/prometheus
#prometheus_version: 25.10.0

#################
# Grafana Options
#################
#enable_grafana: "no"
#grafana_namespace: "{{ kubez_namespace }}"
# Customize grafana user and password
#grafana_admin_user: admin
#grafana_admin_password: admin

# Whether to enable Grafana persistent storage, default is enabled
# Must be 'true' or 'false', otherwise it will be ignored by the helm_toolbox module
#enable_grafana_persistent_volume: 'true'
#grafana_storage_class: managed-nfs-storage
#grafana_persistence_size: 10Gi

# Helm repository configuration
#grafana_repo_name: "{{ default_repo_name }}"
#grafana_repo_url: "{{ default_repo_url }}"
#grafana_path: pixiuio/grafana
#grafana_version: 7.2.4

##############
# Loki Options
##############
#enable_loki: "no"
#loki_namespace: "{{ kubez_namespace }}"

# Storage class to be used
#loki_storage_class: managed-nfs-storage
# Size of persistent disk
#loki_storage_size: 10Gi
# Should authentication be enabled
#loki_auth_enabled: 'false'

# Number of replicas
#loki_commonConfig_replication_factor_number: 2
# Number of customized loki read-write replicas
#loki_read_replicas_number: 3
#loki_write_replicas_number: 3

# Storage config
#loki_storage_bucketNames_chunks: chunks
#loki_storage_bucketNames_ruler: ruler
#loki_storage_bucketNames_admin: admin

# S3 config
s3:
  endpoint: http://172.17.16.13:9000
  secretAccessKey: minioadmin
  accessKeyId: minioadmin
  s3ForcePathStyle: true
  insecure: true

# helm repository configuration
#loki_repo_name: "{{ default_repo_name }}"
#loki_repo_url: "{{ default_repo_url }}"
#loki_path: pixiuio/loki
#loki_version: 5.41.8

##################
# promtail Options
##################
#enable_promtail: "no"
#promtail_namespace: "{{ kubez_namespace }}"

# Loki server url for push
#loki_url: http://loki-gateway/loki/api/v1/push

# helm repository configuration
#promtail_repo_name: "{{ default_repo_name }}"
#promtail_repo_url: "{{ default_repo_url }}"
#promtail_path: pixiuio/promtail
#promtail_version: 6.15.4

#################
# hoggie Options
#################
#enable_loggie: "no"
#loggie_namespace: "{{ kubez_namespace }}"

#loggie_loki_url: http://loki-gateway/loki/api/v1/push
# helm repository configuration
#loggie_repo_name: "{{ default_repo_name }}"
#loggie_repo_url: "{{ default_repo_url }}"
#loggie_path: pixiuio/loggie
#loggie_version: 1.4.0

##################
# metallb Options
##################
#enable_metallb: "no"
#metallb_namespace: "{{ kubez_namespace }}"

###############
# Helm Options
###############
#enable_helm: "yes"

# v3.5.2 and v3.9.0 are available; default is v3.9.0
#helm_release: v3.9.0
#helm_image: "harbor.cloud.pixiuio.com/pixiuio/helm-toolbox:{{ helm_release }}"

########################
# Elasticsearch Options
########################
# The Fluentd, Elasticsearch, and Kibana will be installed when enabled.
#enable_elasticsearch: "no"
#elasticsearch_name: elasticsearch
#elasticsearch_namespace: "{{ kubez_namespace }}"
#elasticsearch_chart_version: 8.5.1

# Recommended for production environment
#elasticsearch_replicas: 3
# Production environment requires at least 2 nodes
#minimum_master_nodes: 2


###################
# Filebeat Options
###################
#enable_filebeat: "no"
#filebeat_name: filebeat
#filebeat_namespace: "{{ kubez_namespace }}"
#filebeat_chart_version: 8.5.1

#################
# Kibana Options
#################
#enable_kibana: "no"
#kibana_name: kibana
#kibana_namespace: "{{ kubez_namespace }}"
#kibana_chart_version: 8.5.1
#kibana_replicas: 1

##################
# Fluentd Options
##################
#enable_fluentd: "no"
#fluentd_name: fluentd
#fluentd_namespace: "{{ kubez_namespace }}"
#fluentd_chart_version: 0.3.9

######################
# Artifactory Options
######################
#enable_artifactory: "no"

#artifactory_namespace: "{{ kubez_namespace }}"
#artifactory_storage_class: managed-nfs-storage
#artifactory_size: "20Gi"
#postgresql_size: "20Gi"

##################
# Jenkins Options
##################
#enable_jenkins: "no"
#jenkins_namespace: "{{ kubez_namespace }}"
#jenkins_storage_class: managed-nfs-storage
#jenkins_storage_size: 8Gi

# The initial password for admin
#initial_admin_password: admin123456

# helm repository configuration item, defaults to Pixiu Helm chart repository
#jenkins_repo_name: "{{ default_repo_name }}"
#jenkins_repo_url: "{{ default_repo_url }}"
#jenkins_path: pixiuio/jenkins
#jenkins_version: 4.12.0

#################
# Tekton Options
#################
#enable_tekton: "no"

#######################
# cert-manager Options
#######################
# enable_cert_manager: "no"

# cert_manager_names: cert-manager
# cert_manager_namespace: "{{ kubez_namespace }}"

#################
# Harbor Options
#################
#enable_harbor: "no"
#harbor_name: harbor
#harbor_namespace: "{{ kubez_namespace }}"
#harbor_storage_size: "5Gi"
#harbor_admin_password: "Harbor12345"

#expose_http_nodeport: 30011
#expose_notary_nodeport: 30012

# Setting it to "keep" to avoid removing PVCs during a helm delete
# operation. Leaving it empty will delete PVCs after the chart deleted
# (this does not apply for PVCs that are created for internal database
# and redis components, i.e. they are never deleted automatically)
#harbor_resource_policy: " "

# Valid options are [ ingress, nodePort ]
#expose_type: nodePort
#expose_core_domain: core.harbor.kubez.com
#expose_notary_domain: notary.harbor.kubez.com
#harbor_storage_class: managed-nfs-storage

####################################
# Operator-Lifecycle-Manager Options
####################################
#enable_olm: "no"

##################
# Postgres Options
##################
#enable_postgres: "no"

#postgres_name: postgres
#postgress_namespace: operators

###############
# Redis Options
###############
#enable_redis: "no"

#redis_name: redis
#redis_namespace: operators

##################
# MongoDB Options
##################
#enable_mongodb: "no"

#mongodb_name: mongodb
#mongodb_namespace: operators

##################
# kafka Options
##################
#enable_kafka: "no"

#kafka_name: kafka
#kafka_namespace: operators

##################
# RabbitMQ Options
##################
#enable_rabbitmq: "no"

#rabbitmq_name: rabbitmq
#rabbitmq_namespace: operators

###########################
# Kubez-autoscaler Options
###########################
#enable_hpav2: "no"

################
# Istio Options
################
#enable_istio: "no"
#istio_chart_version: "1.16.1"

#######################
# Ingress Nginx Options
#######################
#enable_ingress_nginx: "yes"

#######################
# Metrics Server Options
#######################
#enable_metrics_server: "yes"

####################
# Chaos Mesh Options
####################
# https://chaos-mesh.org/docs/production-installation-using-helm/
#enable_chaos_mesh: "no"
#chaos_mesh_chart_version: "2.6.2"

#chaos_mesh_name: chaos-mesh
#chaos_mesh_namespace: "{{ kubez_namespace }}"
#socket_path: /var/run/docker.sock
#runtime: docker


################
# Cilium Options
################
# https://docs.cilium.io/en/stable/overview/intro/
#enable_cilium: "no"
#cilium_chart_version: 1.14.5
#cilium_namespace: kube-system

######################
# Kuberhealthy Options
######################
# https://github.com/kuberhealthy/kuberhealthy
#enable_kuberhealthy: "no"
#kuberhealthy_namespace: pixiu-system
#kuberhealthy_version: "100"

######################
# zookeeper
######################
#enable_zookeeper: "no"
# helm configuration
#zookeeper_repository_name: "{{ default_repo_name }}"
#zookeeper_repository_url: "{{ default_repo_url }}"
#zookeeper_repository_path: "{{ default_repo_name }}/zookeeper"
# zookeeper configuration
#zookeeper_replicas: 1
#zookeeper_requests_cpu: 1
#zookeeper_requests_memory: "1Gi"
#zookeeper_namespace: "{{ kubez_namespace }}"
#zookeeper_image_registry: "{{ app_image_repository }}"
#zookeeper_image_repository: "zookeeper"
#zookeeper_version: "11.4.9"
# zookeeper persistence settings
#zookeeper_persistence_enabled: "false"
#zookeeper_persistence_size: "8Gi"
#zookeeper_persistence_storageclass: "{{ nfs_storage_class }}"
#zookeeper_context_fsgroup: "0"

